\chapter{Discussions}\label{chapter:discussions}

\section{Performance Findings}
\subsection{Effect of Prefetch Count}
\label{subsec:discussion-prefetch}
  In the observations made in \autoref{fig:result-prefetch}, the scaling up of throughput scaled up almost linearly up to 8 consumers for every prefetch-count (except when the prefetch-count was 16). Adding more consumers after 8 resulted in the decrease of throughput, which is quite similar to the result of benchmark~[\autoref{fig:rabbitmqBenchmark}] of RabbitMQ described in ~\autoref{subsec:rabbitmqPrefetch}. In the benchmark of RabbitMQ, the decline of throughput were seen when there are around 8 to 10 consumers.

  The greater the number of consumers, the more work required by RabbitMQ to keep track of the consumers. Hence, it could be the same reason we saw the decline in performance with more number of consumers in \autoref{fig:result-prefetch}.

  In a distributed system, the cause of a sudden performance change could be because of number of factors like network speed, the system in which the isolate system is running or because of the bottle necking in a Message Queuing System, which is the gateway of all the messages. But each time the performance seems to drop after around 8 consumers. The number of consumers after which the decline in performance occurred in \autoref{subsec:rabbitmqPrefetch} and \autoref{fig:result-prefetch} suggests that the reason could be because of message broker system requiring to handle too many consumers for a queue.

\subsection{Effect of Message Size}
  From \autoref{fig:result-consumptionMessageSize} and \autoref{fig:result-productionMessageSize} from \autoref{subsec:messageSize}, we can observe the negative impact of increase in message size. Nevertheless, if we assess the amount by which the performance decreased, we can see that doubling the message size did not cause halving of the performance. Thus, from this finding we can infer that instead of two separate chunks of messages, if we send messages as a big chunk the overall throughput increases. For instance, let's consider the results of 64-bytes messages and 1024-bytes messages. The throughput of 64-bytes messages was 8400 whereas that of 1024 was 3097. If we assume that the 1024-Bytes message was the concatenation of sixteen 64-Bytes messages, then the overall throughput would become 49552 messages per second. The overall increment of throughput by about 6 times! This means that for small messages, time is spent more on processing rather than on Input/Output.

  The similar case for production throughput can be seen in \autoref{fig:result-productionMessageSize}. With similar calculations for 64-bytes messages and 1024-bytes messages, if the messages are chunked together, we can gain approximately 13 times greater throughput.

  Nevertheless, such concatenation may not always be feasible and may prove to be against the fair distribution of messages across systems. However, if it is appropriate to concat multiple messages in certain systems, then finding an optimum size (by considering the other requirements of the application) of a message which gives maximizes throughput might prove to be quite beneficial.

\subsection{Effect of Scaling out Message Queuing System}
  The scaling out of MQS clearly had positive impact on overall throughput. Higher number of MQS also allowed to have more consumers with good overall performance. The decline of performance seen in tests with 1 MQS and 2 MQS were probably because of the behavior of RabbitMQ when too many consumers are connected as we discussed in~\autoref{subsec:discussion-prefetch}. But, the test seen with four MQS suggests otherwise. With four MQS, 32 consumers were supported without drop in performance. From which, we can speculate that MQS might also be causing the limit in the throughput as MQS has to distribute messages to the connected systems. The more the consumers connected to MQS, the more the CPU time and memory it requires.

\subsection{Comparision of production throughputs}
  As seen in ~\autoref{fig:result-productionIsolate} and ~\autoref{fig:result-productionMessageSize}, the difference seen between the throughput at a worker isolate and throughput at RabbitMQ is quite significant. This is because the production of message in an isolate is localized to one particular instance before the message is transferred to MQS over WebSocket. Thus, it is natural the production of isolates are that high. Nonetheless, when the overall producers were increased, although overall message production throughput increased, average throughput per isolate declined. One possible explanation to this behavior could be the bottle necking at MQS to which all of these producers send message. The explanation might seem strange because sending messages in isolate are asynchronous. So, it should not have been affected by a outside decoupled component. But, the reason behind this speculation is that since MQS cannot accept messages at the rate which it is produced, the messages get buffered in the internal queues of top level isolates. This takes up more heap memory reserved for the isolate and so it starts to get slower and the similar effect probably occurs in Controller isolate and then in Router isolate and ultimately in Worker isolate, each of them buffering more messages into internal queue. Hence, as the available heap memory of Worker isolate becomes lower the production throughput decreases.

\subsection{Effect of Simultaneous Production and Consumption}
In \autoref{fig:result-simultaneous1}, we can see the negative impact of starting producer along with consumer when producer was producing messages continuously. Again, when the producers and consumers were split to connect to separate instances of MQS, the performance improvement was more prominent in message consumption.
  By comparing \autoref{fig:result-simultaneous1} and \autoref{fig:result-simultaneous2}, the culprit of this behavior seems to be the MQS. The MQS, even though has separate isolates for Enqueuer and Dequeuer, has only one top level isolate~\autoref{subsec:mqs}. Obviously when there is a large quantity of messages from producer in queue, the dequeue requests that arrive from the consumer isolate as well as the the dequeued messages that arrive from Dequeuer goes further back in the internal isolate queue. The improvement of consumption throughput seen in
   \autoref{fig:result-simultaneous2} also supports this explanation because in this case, the MQS where consumers are connected does not have to deal with the large surge of production messages. Thus, the dequeue requests and dequeued messages from Dequeuer get processed much quicker compared to previous case.

\subsection{Throughput of Request-Reply}
  The benchmark of request-reply ~\autoref{subsec:request-reply} showed almost linear increment with increase in number of requesters. But, increase in number of suppliers from 1 to 8 had little effect in overall performance. The reason behind this could be the design of the program which uses \emph{ask} method to send message. Based on how \emph{ask} works~[\autoref{itm:askWorking}] as discussed in \autoref{subsec:implementationOverview}, even a single supplier might not have been saturated with the number of requesters it could handle. A slight increase was seen with more supplier, but this is quite minimal and could have been affected by any other factors like RabbitMQ performance, change in network latency, etc. There is not enough data and evidence to support the idea of big improvement in throughput with more suppliers. Testing with more number of consumers till the supplier saturate would yield better result and better idea of what affects throughput of request-reply.


\section{The Framework}

\subsection{Scalability}
    Scalable at different component levels. Isolates, Isolate System, Message Queuing System and clustering of Message Broker (RabbitMQ). Better scalability is obtained when the Message Queuing System is scaled out.

\subsection{Availability}
    Can be designed to make highly available. Apparently, no downtime to deploy new code to a running system.

  \subsection{Reliability}


\section{Problems/Issues}
\subsection{Dart Induced Issues}
  \begin{itemize}
  \item The Unimplemented functionalities of Isolates
    - KILL, PAUSE, PING, Supervision of Isolates
  \item Isolate are not lightweight.
  \item Running Isolates in web (Dartium)
\end{itemize}
